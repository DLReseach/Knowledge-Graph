{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "import gc, os\n",
    "import jsons\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import datetime\n",
    "import uuid\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import joblib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.read_excel(\"enron_metrics.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Entity:\n",
    "    def __init__(self, entity_id):\n",
    "        self.type = \"entity\"\n",
    "        self.entity_id = entity_id\n",
    "        self.dp = {\"entity_id\":self.entity_id, \"type\":self.type}\n",
    "        \n",
    "    def to_dict(self):\n",
    "        return (self.dp)\n",
    "        \n",
    "        \n",
    "class Person(Entity):\n",
    "    def __init__(self, entity_id, full_name):\n",
    "        super().__init__(entity_id)\n",
    "        self.dp[\"object_name\"] = self.object_name = \"person\"\n",
    "        self.dp[\"full_name\"] = self.full_name = full_name\n",
    "   \n",
    "   \n",
    "    \n",
    "class Position(Entity):\n",
    "    def __init__(self, entity_id, position):\n",
    "        super().__init__(entity_id)\n",
    "       \n",
    "        self.dp[\"object_name\"] = self.object_name = \"position\"\n",
    "        self.dp[\"position\"] = self.position = position\n",
    "    \n",
    "\n",
    "class Attribute(Entity):\n",
    "    def __init__(self, entity_id, hub_score, is_good_hub, auth_score, is_good_auth, betweenness_score, is_middle_person):\n",
    "        super().__init__(entity_id)\n",
    "\n",
    "        self.dp[\"object_name\"] = self.object_name = \"attribute\"\n",
    "        self.dp[\"hub_score\"] = self.hub_score = hub_score\n",
    "        self.dp[\"is_good_hub\"] = self.is_good_hub = is_good_hub\n",
    "        self.dp[\"auth_score\"] = self.auth_score = auth_score \n",
    "        self.dp[\"is_good_auth\"] = self.is_good_auth = is_good_auth\n",
    "        self.dp[\"betweenness_score\"] = self.betweenness_score = betweenness_score\n",
    "        self.dp[\"is_middle_person\"] = self.is_middle_person = is_middle_person\n",
    "                \n",
    "        \n",
    "class Email(Entity):\n",
    "    def __init__(self, entity_id, subject):\n",
    "        super().__init__(entity_id)\n",
    "        self.dp[\"object_name\"] = self.object_name = \"email\"\n",
    "        self.dp[\"subject\"] = self.subject = subject\n",
    "\n",
    "    \n",
    "\n",
    "class Topic(Entity):\n",
    "    def __init__(self, entity_id, topic):\n",
    "        super().__init__(entity_id)\n",
    "        self.dp[\"object_name\"] = self.object_name = \"topic\"\n",
    "        self.dp[\"topic\"] = self.topic = topic\n",
    "          \n",
    "        \n",
    "\n",
    "class Relationship:\n",
    "    def __init__(self, relationship_id):\n",
    "        self.type = \"relationship\"\n",
    "        self.relationship_id = relationship_id\n",
    "        self.dp = {\"relationship_id\":self.relationship_id, \"type\":self.type}\n",
    "    def to_dict(self):\n",
    "        return (self.dp)\n",
    "        \n",
    "    \n",
    "class Sends(Relationship):\n",
    "    def __init__(self, relationship_id, datetime):\n",
    "        super().__init__(relationship_id)\n",
    "        self.dp[\"object_name\"] = self.object_name = \"sends\"\n",
    "        self.dp[\"datetime\"] = self.datetime = datetime\n",
    "        self.dp[\"year\"] = self.year = datetime.year\n",
    "        self.dp[\"month\"] = self.month = datetime.month\n",
    "        self.dp[\"day\"] = self.day = datetime.day\n",
    "        \n",
    "        \n",
    "class Receives(Relationship):\n",
    "    def __init__(self, relationship_id, datetime):\n",
    "        super().__init__(relationship_id)\n",
    "        self.dp[\"object_name\"] = self.object_name = \"receives\"\n",
    "        self.dp[\"datetime\"] = self.datetime = datetime\n",
    "        self.dp[\"year\"] = self.year = datetime.year\n",
    "        self.dp[\"month\"] = self.month = datetime.month\n",
    "        self.dp[\"day\"] = self.day = datetime.day\n",
    "        \n",
    "class CCed(Relationship):\n",
    "    def __init__(self, relationship_id, datetime):\n",
    "        super().__init__(relationship_id)\n",
    "        self.dp[\"object_name\"] = self.object_name = \"CCed\"\n",
    "        self.dp[\"datetime\"] = self.datetime = datetime\n",
    "        self.dp[\"year\"] = self.year = datetime.year\n",
    "        self.dp[\"month\"] = self.month = datetime.month\n",
    "        self.dp[\"day\"] = self.day = datetime.day\n",
    "        \n",
    "class BCCed(Relationship):\n",
    "    def __init__(self, relationship_id, datetime):\n",
    "        super().__init__(relationship_id)\n",
    "        self.dp[\"object_name\"] = self.object_name = \"BCCed\"\n",
    "        self.dp[\"datetime\"] = self.datetime = datetime\n",
    "        self.dp[\"year\"] = self.year = datetime.year\n",
    "        self.dp[\"month\"] = self.month = datetime.month\n",
    "        self.dp[\"day\"] = self.day = datetime.day\n",
    "\n",
    "class Is(Relationship):\n",
    "    def __init__(self, relationship_id):\n",
    "        super().__init__(relationship_id)\n",
    "        self.dp[\"object_name\"] = self.object_name = \"is\"\n",
    "\n",
    "class Has(Relationship):\n",
    "    def __init__(self, relationship_id):\n",
    "        super().__init__(relationship_id)\n",
    "        self.dp[\"object_name\"] = self.object_name = \"has\"\n",
    "        \n",
    "class Contains(Relationship):\n",
    "    def __init__(self, relationship_id, weight):\n",
    "        super().__init__(relationship_id)\n",
    "        self.dp[\"object_name\"] = self.object_name = \"contains\"\n",
    "        self.dp[\"weight\"] = self.object_name = weight\n",
    "\n",
    "class Interacts_with(Relationship):\n",
    "    def __init__(self, relationship_id, weight):\n",
    "        super().__init__(relationship_id)\n",
    "        self.dp[\"object_name\"] = self.object_name = \"interacts_with\"\n",
    "        self.dp[\"weight\"] = self.weight = weight\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnx = mysql.connector.connect(user='root', password='shawn672000',\n",
    "                              host='localhost',\n",
    "                              database='enron')\n",
    "g = cnx.cursor()\n",
    "\n",
    "q =  \"SELECT * FROM message\"\n",
    "msgs = pd.read_sql(con=cnx, sql=q)\n",
    "\n",
    "msgs[\"mid\"] = msgs.mid.apply(lambda x: str(x)+\"email\")\n",
    "msgs.drop(\"message_id\", axis=1, inplace=True)\n",
    "\n",
    "q = \"SELECT * FROM recipientinfo\"\n",
    "recp = pd.read_sql(con=cnx, sql=q)\n",
    "recp[\"rid\"] = recp[\"rid\"].apply(lambda x: str(x)+\"empl\")\n",
    "recp[\"mid\"] = recp[\"mid\"].apply(lambda x: str(x)+\"email\")\n",
    "\n",
    "q = \"\"\"SELECT DISTINCT * FROM\n",
    "(SELECT eid,  concat(firstName, ' ', lastName) AS employee_name, Email_id as email_id, status AS position FROM enron.employeelist UNION\n",
    "SELECT eid,  concat(firstName, ' ', lastName) AS employee_name, Email2 as email_id, status AS position FROM enron.employeelist UNION\n",
    "SELECT eid, concat(firstName, ' ', lastName) AS employee_name, Email3 as email_id, status AS position FROM enron.employeelist UNION\n",
    "SELECT eid, concat(firstName, ' ', lastName) AS employee_name, Email4 as email_id, status AS position FROM enron.employeelist) s\"\"\"\n",
    "\n",
    "emp = pd.read_sql(con=cnx, sql=q)\n",
    "emp[\"eid\"] = emp[\"eid\"].apply(lambda x:str(x)+\"empl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs = msgs.merge(emp, how=\"inner\", right_on=\"email_id\", left_on=\"sender\")\n",
    "recp = recp.merge(emp, how = \"inner\", left_on=\"rvalue\", right_on=\"email_id\")\n",
    "msgs = msgs.merge(recp, how=\"inner\", left_on=\"mid\", right_on=\"mid\", suffixes=[\"_msg\", \"_rec\"])\n",
    "msgs = msgs[msgs.eid_msg != msgs.eid_rec].reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp = emp[[\"eid\", \"employee_name\", \"position\"]].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['msgs.joblib']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "joblib.dump(value=msgs, filename=\"msgs.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs = joblib.load(\"msgs.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs.to_csv(\"msgs.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.MultiDiGraph()\n",
    "emp.position = emp.position.fillna(\"N/A\")\n",
    "for p in emp.position:\n",
    "    pos = Position(entity_id=p, position=p)\n",
    "    G.add_node(pos.entity_id, attr=pos.to_dict())\n",
    "\n",
    "for i in range(len(emp)):\n",
    "    p = Person(emp.iloc[i][\"eid\"], emp.iloc[i][\"employee_name\"])\n",
    "    G.add_node(p.entity_id, attr=p.to_dict())\n",
    "    ep = Is(relationship_id=uuid.uuid1())\n",
    "    G.add_edge(u_for_edge=p.entity_id, v_for_edge=emp.iloc[i][\"position\"], attr=ep.to_dict())\n",
    "\n",
    "for i in range(len(msgs[[\"mid\", \"subject\", \"body\"]])):\n",
    "    msg = msgs[[\"mid\", \"subject\"]].iloc[i]\n",
    "    em = Email(entity_id=msg[\"mid\"], subject=msg[\"subject\"])\n",
    "    G.add_node(em.entity_id, attr=em.to_dict())\n",
    "    \n",
    "\n",
    "msgs_tmp = msgs[[\"mid\", \"date\", \"eid_msg\", \"rtype\", \"eid_rec\"]]\n",
    "\n",
    "\n",
    "for i in range(len(msgs_tmp)):\n",
    "    obj = msgs_tmp.iloc[i]\n",
    "    if obj[\"rtype\"] == \"TO\":\n",
    "        sd = Sends(datetime=obj.date, relationship_id=str(uuid.uuid1()))\n",
    "        G.add_edge(u_for_edge=obj[\"eid_msg\"], v_for_edge=obj[\"mid\"], attr=sd.to_dict())\n",
    "        rd = Receives(datetime=obj.date, relationship_id=str(uuid.uuid1()))\n",
    "        G.add_edge(u_for_edge=obj[\"eid_rec\"], v_for_edge=obj[\"mid\"], attr=rd.to_dict())\n",
    "    elif obj[\"rtype\"] == \"CC\":\n",
    "        rd = CCed(datetime=obj.date, relationship_id=str(uuid.uuid1()))\n",
    "        G.add_edge(u_for_edge=obj[\"mid\"], v_for_edge=obj[\"eid_rec\"], attr=rd.to_dict())\n",
    "    elif obj[\"rtype\"] == \"BCC\":\n",
    "        rd = BCCed(datetime=obj.date, relationship_id=str(uuid.uuid1()))\n",
    "        G.add_edge(u_for_edge=obj[\"mid\"], v_for_edge=obj[\"eid_rec\"], attr=rd.to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_id = msgs[[\"eid_msg\", \"eid_rec\"]].reset_index(drop=True)\n",
    "edges_id[\"weight\"] = 0\n",
    "edges_id = edges_id.groupby(by=[\"eid_msg\", \"eid_rec\"]).count().reset_index()\n",
    "\n",
    "for i in range(len(edges_id)):\n",
    "    obj = edges_id.iloc[i]\n",
    "    iw = Interacts_with(relationship_id=str(uuid.uuid1()), weight=obj[\"weight\"])\n",
    "    G.add_edge(u_for_edge=obj[\"eid_msg\"], v_for_edge=obj[\"eid_rec\"], attr=iw.to_dict())\n",
    "\n",
    "emp = emp[[\"eid\", \"employee_name\"]].drop_duplicates().reset_index(drop=True)\n",
    "metrics = metrics.merge(emp, left_index=True, right_on=\"employee_name\", how=\"inner\")\n",
    "\n",
    "metrics_grp = metrics[['hub_auth_clus', \"hub\", \"auth\"]].groupby(by=['hub_auth_clus']).mean()\n",
    "\n",
    "metrics_grp[\"argmax\"] = metrics_grp[[\"hub\", \"auth\"]].idxmax(axis=1)\n",
    "\n",
    "high_auth_clus = metrics_grp[metrics_grp[\"argmax\"] == \"auth\"].sort_values(by=\"auth\", ascending=False).head(1).index[0]\n",
    "high_hub_clus = metrics_grp[metrics_grp[\"argmax\"] == \"hub\"].sort_values(by=\"hub\", ascending=False).head(1).index[0]\n",
    "\n",
    "metrics_grp[\"is_good_hub\"] = \"no\"\n",
    "metrics_grp.at[high_hub_clus, \"is_good_hub\"] = \"yes\"\n",
    "metrics_grp[\"is_good_auth\"] = \"no\"\n",
    "metrics_grp.at[high_auth_clus, \"is_good_auth\"] = \"yes\"\n",
    "\n",
    "metrics_grp.drop([\"hub\", \"auth\", \"argmax\"], axis=1, inplace=True)\n",
    "metrics_grp_bet = metrics[['close_and_between_clus', \"c_betweenness\"]].groupby(by=['close_and_between_clus']).mean()\n",
    "is_middle = metrics_grp_bet.sort_values(by=[\"c_betweenness\"], ascending=False).head(1).index.values\n",
    "metrics_grp_bet[\"is_middle_person\"] = \"no\"\n",
    "metrics_grp_bet.at[is_middle, \"is_middle_person\"] = \"yes\"\n",
    "metrics_grp_bet.drop(\"c_betweenness\", axis=1, inplace=True)\n",
    "\n",
    "\n",
    "metrics = metrics[['c_betweenness', 'hub', 'auth', 'close_and_between_clus', 'hub_auth_clus', 'eid']]\n",
    "metrics[[\"is_good_hub\", \"is_good_auth\"]] = metrics.hub_auth_clus.apply(lambda x: metrics_grp.loc[x])\n",
    "metrics[\"is_middle_person\"] = metrics.close_and_between_clus.apply(lambda x: metrics_grp_bet.loc[x])\n",
    "metrics[\"attr_id\"] = metrics.eid.str.replace(\"empl\", \"attr\")\n",
    "\n",
    "metrics.drop([\"close_and_between_clus\", \"hub_auth_clus\"], axis=1, inplace=True)\n",
    "\n",
    "for i in range(len(metrics)):\n",
    "    obj = metrics.iloc[i]\n",
    "    att = Attribute(auth_score=obj[\"auth\"], entity_id=obj[\"attr_id\"], is_good_auth=obj[\"is_good_auth\"], \n",
    "                    is_middle_person=obj[\"is_middle_person\"], is_good_hub=obj[\"is_good_hub\"], \n",
    "                    betweenness_score=obj[\"c_betweenness\"], hub_score=obj[\"hub\"])\n",
    "    \n",
    "    G.add_node(att.entity_id, attr=att.to_dict())\n",
    "\n",
    "for i in range(len(metrics)):\n",
    "    obj = metrics.iloc[i]\n",
    "    h = Has(relationship_id=str(uuid.uuid1()))\n",
    "    G.add_edge(u_for_edge=obj[\"eid\"], v_for_edge=obj[\"attr_id\"], attr=h.to_dict())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gpickle(G=G, path=\"enron_KG.gpickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_gpickle(path=\"enron_KG.gpickle\")\n",
    "mid_topics = np.load('mid_topics.npz')\n",
    "\n",
    "mids = mid_topics[\"mid\"]\n",
    "topics = mid_topics[\"topics\"]\n",
    "email_topics = mid_topics[\"email_topics\"]\n",
    "feature_names = mid_topics[\"feature_names\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = np.apply_along_axis(arr = topics[:,:,0], axis=1, func1d=lambda x:\",\".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(topics.shape[0]):\n",
    "    tp = Topic(entity_id=i, topic=topics[i])\n",
    "    G.add_node(tp.entity_id, attr=tp.to_dict())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_t = np.argmax(email_topics, axis=1)\n",
    "weight = np.max(email_topics, axis=1)\n",
    "for mid, tp, wt in zip(mids, email_t, weight):\n",
    "          \n",
    "    con = Contains(relationship_id=str(uuid.uuid1()), weight=wt)\n",
    "    G.add_edge(mid, tp, attr=con.to_dict())\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gpickle(G=G, path=\"enron_KG_full.gpickle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
